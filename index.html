<!DOCTYPE html>
<html>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Louis Bradshaw</title>
        <link href="https://fonts.googleapis.com/css?family=Lato:400,700&display=swap" rel="stylesheet">
        <style>
            body { 
                max-width: 750px;
                line-height: 1.2;
                font-size: 16px;
                margin: 0 auto;
                font-family: 'Lato', Verdana, Helvetica, sans-serif;
            }
            #main {
                margin-left: 10px;
                margin-right: 10px;
                margin-top: 40px;
                margin-bottom: 40px;
            }
            p, li {
                overflow-wrap: break-word;
                word-wrap: break-word;
                hyphens: auto;
                text-align: justify;
            }
            li {
            margin-bottom: 10px; /* Add space between list items */
            }
            li:last-child {
                margin-bottom: 0; /* Remove margin from the last item */
            }
            p {
                margin-top: 0.5em;
                margin-bottom: 0.5em;
            }
            h4 {
                margin-top: 2em; 
            }
            figcaption {
                color: grey;
                margin-bottom: 10px; /* Add space after the subtitle */
            }
            .email-reverse {
                unicode-bidi: bidi-override;
                direction: rtl;
            }
            a {
                color: #1772d0;
                text-decoration: none;
            }
            a:focus, a:hover {
                color: #f09228;
                text-decoration: none;
            }
        </style>

    </head>
    <body>
        <div id="main">
            <h3>Louis Bradshaw</h3>
            <h5><a href="https://drive.google.com/file/d/1RMEZFuwBYVqbBX65mDDIvrIq1lT1xr-K/view?usp=sharing">Curriculum Vitae</a> 
                / <a href="https://github.com/loubbrad">GitHub</a> 
                / <a href="https://twitter.com/loubbrad">Twitter</a>
                <br><span class="email-reverse"> ku.ca.lumq@wahsdarb.b.l</span></h5>

            <p>I'm a CS/ML PhD student at <a href="https://www.c4dm.eecs.qmul.ac.uk/">C4DM</a>, where I specialize in Deep Learning for Music. I'm also a research lead at <a href="https://www.eleuther.ai/">EleutherAI</a>. Prior to my PhD I studied Mathematics, focusing on Algebra and Geometry.
                My current research interests are varied and include:
            </p>

            <ul>
                <li><b>Multimodal Foundation Models for Music</b>: My primary research focus is building deep learning based generative models 
                    which are expressive, useful, and artistically interesting. My current research project (see the <a href="https://github.com/EleutherAI/aria">Aria</a> project), 
                    which has attracted generous support from both StabilityAI & EleutherAI, 
                    revolves around building a multimodal foundation model, incorporating both audio, e.g., musical recordings, and MIDI (symbolic, note-level information).
                <li><b>Robustness in Audio-to-Seq Models</b>: 
                    I'm interested in improving real-world usability of audio-to-seq models, such as those used for music transcription and speech recognition.
                    I pioneered a semi-supervised approach to training music transcription models (see <a href="https://github.com/EleutherAI/aria-amt">Aria-AMT</a>), enabling audio-to-sequence models to utilize additional information learned from unsupervised data (e.g., note-level <i>tokens</i> without corresponding audio)
                    when transcribing audio. This approach led to state-of-the-art results on the relevant benchmarks. Going forward, I am interested in applying similar techniques to other seq-to-seq problems.
                <li><b>Datasets</b>: 
                    My research into music transcription began in an effort to increase the amount (and quality) of data available for training symbolic music models.
                    Using our transcription model, we created a dataset of realistic, expressive piano transcriptions, comprising over 100,000 hours of music, representing a 100-fold increase over pre-existing datasets.
            </ul>
            
            <p>
                Outside of research, I'm extremely interested in the engineering problems surrounding ML/DL. In my non-research time, I currently dedicate a portion to learning C++/CUDA
                and staying up-to-date with research in ML-infra. Personally speaking, I love mathematics, physics, music, reading, and painting. The best part of doing a PhD is getting to learn 
                from all kinds of people. If you are interested in collaborating, or just chatting about research, feel free to reach out!
            </p>

            <h4>Aria Project</h4>

            <div align="center">
                <p>I currently run a research project on building, scaling, and aligning transformer models for symbolic music. The project 
                    gets its codename, <i>Aria</i>, from the <a href="https://www.youtube.com/watch?v=p4yAB37wG5s">Goldberg Variations</a>, and has
                    attracted generous funding and compute support from both EleutherAI & StabilityAI. Other than building a powerful foundation 
                    model and personal artistic projects, my secondary aim is to build a generative compositional tool which is interesting and useful 
                    to both novices and experts alike. Although this project is still a work in progress and hasn't been publicly released, here are 
                    some early samples showcasing what it can do.</p>
            
            <div>
              <figure style="text-align:center;display:inline-block">
               <figcaption>
                Jazz in the style of Bill Evans
               </figcaption>
               <audio controls=""><source src="assets/aria-mp3/evans.mp3" type="audio/mpeg" /></audio>
              </figure>
              <figure style="text-align:center;display:inline-block">
               <figcaption>
                Piano cover of Yesterday by the Beatles
               </figcaption>
               <audio controls=""><source src="assets/aria-mp3/yesterday.mp3" type="audio/mpeg" /></audio>
              </figure>
              <figure style="text-align:center;display:inline-block">
               <figcaption>
                An original relaxing nocturne
               </figcaption>
               <audio controls=""><source src="assets/aria-mp3/nocturne.mp3" type="audio/mpeg" /></audio>
              </figure>
            </div>
                
            <p>If you are interested finding out more about the Aria project, the best place is on the EleutherAI <a href="https://discord.com/invite/zBGx3azzUn">discord channel</a>.</p>

            </div>
            
            <h4>Misc</h4>
                
            <p>These essays 
                [<a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html">1</a>, 
                <a href="https://www.arvindguptatoys.com/arvindgupta/mathsapology-hardy.pdf">2</a>] 
                and these books
                [<a href="https://en.wikipedia.org/wiki/Cannery_Row_(novel)">3</a>, 
                <a href="https://en.wikipedia.org/wiki/Crime_and_Punishment">4</a>, 
                <a href="https://en.wikipedia.org/wiki/Surely_You%27re_Joking,_Mr._Feynman!">5</a>] 
                had a big influence on me.</p>
        </div>
    </body>
</html>
